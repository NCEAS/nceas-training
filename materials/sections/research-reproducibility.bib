
@article{marwick_packaging_2018,
	title = {Packaging {Data} {Analytical} {Work} {Reproducibly} {Using} {R} (and {Friends})},
	volume = {72},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2017.1375986},
	doi = {10.1080/00031305.2017.1375986},
	abstract = {Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	number = {1},
	urldate = {2019-02-14},
	journal = {The American Statistician},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = jan,
	year = {2018},
	keywords = {provenance, Reproducible research, Open source software, Computational science, Data science},
	pages = {80--88},
	file = {Full Text PDF:/Users/jones/Zotero/storage/RBFSCMSK/Marwick et al. - 2018 - Packaging Data Analytical Work Reproducibly Using .pdf:application/pdf;Snapshot:/Users/jones/Zotero/storage/JW52UK5V/00031305.2017.html:text/html},
}

@article{baker_transparency_2010,
	title = {Transparency and reproducibility in data analysis: the {Prostate} {Cancer} {Prevention} {Trial}},
	volume = {11},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2883301&tool=pmcentrez&rendertype=abstract},
	abstract = {With the analysis of complex, messy data sets, the statistics community has recently focused attention on "reproducible research," namely research that can be readily replicated by others. One standard that has been proposed is the availability of data sets and computer code. However, in some situations, raw data cannot be disseminated for reasons of confidentiality or because the data are so messy as to make dissemination impractical. For one such situation, we propose 2 steps for reproducible research: (i) presentation of a table of data and (ii) presentation of a formula to estimate key quantities from the table of data. We illustrate this strategy in the analysis of data from the Prostate Cancer Prevention Trial, which investigated the effect of the drug finasteride versus placebo on the period prevalence of prostate cancer. With such an important result at stake, a transparent analysis was important.},
	number = {3},
	journal = {Biostatistics Oxford England},
	author = {Baker, Stuart G and Darke, Amy K and Pinsky, Paul and Parnes, Howard L and Kramer, Barnett S},
	year = {2010},
	keywords = {categorical data, maximum likelihood, missing data, multinomial–poisson transformation, propensity missing score, randomized trials},
	pages = {413--418},
}

@article{schwab_making_2000,
	title = {Making {Scientific} {Computations} {Reproducible}},
	volume = {2},
	issn = {15219615},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=881708},
	doi = {10.1109/5992.881708},
	abstract = {To verify a research paper's computational results, readers typically have to recreate them from scratch. ReDoc is a simple software filing system for authors that lets readers easily reproduce computational results using standardized rules and commands},
	number = {6},
	journal = {Computing in Science Engineering},
	author = {Schwab, Matthias and Karrenbach, Martin and Claerbout, Jon},
	year = {2000},
	pages = {61--67},
}

@article{stodden_legal_2009,
	title = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}: {Licensing} and {Copyright}},
	volume = {11},
	issn = {1521-9615},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4720221},
	doi = {10.1109/MCSE.2009.19},
	number = {1},
	journal = {Computing in Science \& Engineering},
	author = {Stodden, Victoria},
	month = jan,
	year = {2009},
	pages = {35--40},
	file = {Attachment:/Users/jones/Zotero/storage/PD9UEJ7N/stodden-repro-research-ieee-2009.pdf:application/pdf;Attachment:/Users/jones/Zotero/storage/NTKNR4AW/stodden-repro-research-copyright.pdf:application/pdf},
}

@article{gentleman_reproducible_2005,
	title = {Reproducible research: a bioinformatics case study.},
	volume = {4},
	url = {http://www.bepress.com/sagmb/vol4/iss1/art2},
	abstract = {While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2003), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang (2003) propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output - thereby providing the familiar, but limited, static document. {\textless}p In this paper we apply these concepts to a seminal paper in bioinformatics, namely The Molecular Classification of Cancer, Golub et al (1999). The authors of that paper have generously provided data and other information that have allowed us to largely reproduce their results. Rather than reproduce this paper exactly we demonstrate that such a reproduction is possible and instead concentrate on demonstrating the usefulness of the compendium concept itself.},
	number = {1},
	journal = {Statistical applications in genetics and molecular biology},
	author = {Gentleman, Robert},
	year = {2005},
	pages = {Article2},
}

@article{cassey_reproducibility_2006,
	title = {Reproducibility and {Repeatability} in {Ecology}},
	volume = {56},
	issn = {00063568},
	url = {http://caliber.ucpress.net/doi/full/10.1641/0006-3568%282006%2956%5B958%3ARARIE%5D2.0.CO%3B2},
	doi = {10.1641/0006-3568(2006)56[958:RARIE]2.0.CO;2},
	abstract = {The quantitative synthesis of researchresults is of fundamental importancein seeking to develop ecologicalgeneralities and construct refutable theories.It is thus critical that publishedstudies contain sufficient detail to allowtheir methods to be replicated and theirresults compared. In response to thisneed, growing attention is being paid tothe publication and presentation of analyticalresults in ecology. Our recent experiencehas been that journal referees(and editors) increasingly express theopinion that results need to be accompaniedby general access to the primarydata on which they are based. Here weargue that the legitimate aims of formalscientific inquiry (including the publicationand validation of results) do notneed to infringe the intellectual propertyrights of publishing ecologists.},
	number = {12},
	journal = {BioScience},
	author = {Cassey, Phillip and Blackburn, Tim M},
	year = {2006},
	keywords = {ISEES},
	pages = {958--959},
	file = {Attachment:/Users/jones/Zotero/storage/A9K984Q4/cassey-2006.pdf:application/pdf},
}

@techreport{et_al._spies_reproducibility_2012,
	title = {The reproducibility of psychological science},
	institution = {Report of the Open Science Collaboration},
	author = {et al. Spies, J.},
	year = {2012},
}

@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	number = {10},
	urldate = {2013-10-28},
	journal = {PLoS Computational Biology},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	editor = {Bourne, Philip E.},
	month = oct,
	year = {2013},
	pages = {e1003285},
	file = {sandve-repro-rules-2013.pdf:/Users/jones/Zotero/storage/DS38MM6I/sandve-repro-rules-2013.pdf:application/pdf},
}

@article{marwick_computational_2017,
	title = {Computational {Reproducibility} in {Archaeological} {Research}: {Basic} {Principles} and a {Case} {Study} of {Their} {Implementation}},
	volume = {24},
	issn = {1072-5369, 1573-7764},
	shorttitle = {Computational {Reproducibility} in {Archaeological} {Research}},
	url = {http://link.springer.com/10.1007/s10816-015-9272-9},
	doi = {10.1007/s10816-015-9272-9},
	language = {en},
	number = {2},
	urldate = {2017-08-28},
	journal = {Journal of Archaeological Method and Theory},
	author = {Marwick, Ben},
	month = jun,
	year = {2017},
	pages = {424--450},
}

@misc{carole_goble_what_nodate,
	type = {Science},
	title = {What is reproducibility? {The} {R}* {Brouhaha}},
	copyright = {License: CC Attribution License},
	url = {https://www.slideshare.net/carolegoble/what-is-reproducibility-gobleclean},
	abstract = {What is Reproducibility? “When I use a word," Humpty Dumpty said in rather a},
	urldate = {2019-02-25},
	author = {Carole Goble},
}

@article{nust_ten_2020,
	title = {Ten simple rules for writing {Dockerfiles} for reproducible data science},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008316},
	doi = {10.1371/journal.pcbi.1008316},
	abstract = {Computational science has been greatly improved by the use of containers for packaging software and data dependencies. In a scholarly context, the main drivers for using these containers are transparency and support of reproducibility; in turn, a workflow’s reproducibility can be greatly affected by the choices that are made with respect to building containers. In many cases, the build process for the container’s image is created from instructions provided in a Dockerfile format. In support of this approach, we present a set of rules to help researchers write understandable Dockerfiles for typical data science workflows. By following the rules in this article, researchers can create containers suitable for sharing with fellow scientists, for including in scholarly communication such as education or scientific papers, and for effective and sustainable personal workflows.},
	language = {en},
	number = {11},
	urldate = {2020-11-18},
	journal = {PLOS Computational Biology},
	author = {Nüst, Daniel and Sochat, Vanessa and Marwick, Ben and Eglen, Stephen J. and Head, Tim and Hirst, Tony and Evans, Benjamin D.},
	month = nov,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Metadata, Reproducibility, Computer software, Computer and information sciences, Habits, Programming languages, Software tools, Source code},
	pages = {e1008316},
	file = {Full Text PDF:/Users/jones/Zotero/storage/MV6PHRBG/Nüst et al. - 2020 - Ten simple rules for writing Dockerfiles for repro.pdf:application/pdf;Snapshot:/Users/jones/Zotero/storage/KU5Z9ITG/article.html:text/html},
}

@article{nust_practical_2020,
	title = {Practical {Reproducibility} in {Geography} and {Geosciences}},
	volume = {0},
	issn = {2469-4452},
	url = {https://doi.org/10.1080/24694452.2020.1806028},
	doi = {10.1080/24694452.2020.1806028},
	abstract = {Reproducible research is often perceived as a technological challenge, but it is rooted in the challenge to improve scholarly communication in an age of digitization. When computers become involved and researchers want to allow other scientists to inspect, understand, evaluate, and build on their work, they need to create a research compendium that includes the code, data, computing environment, and script-based workflows used. Here, we present the state of the art for approaches to reach this degree of computational reproducibility, addressing literate programming and containerization while paying attention to working with geospatial data (digital maps, geographic information systems). We argue that all researchers working with computers should understand these technologies to control their computing environment, and we present the benefits of reproducible workflows in practice. Example research compendia illustrate the presented concepts and are the basis for challenges specific to geography and geosciences. Based on existing surveys and best practices from different scientific domains, we conclude that researchers today can overcome many barriers and achieve a very high degree of reproducibility. If the geography and geosciences communities adopt reproducibility and the underlying technologies in practice and in policies, they can transform the way researchers conduct and communicate their work toward increased transparency, understandability, openness, trust, productivity, and innovation.},
	number = {0},
	urldate = {2021-06-14},
	journal = {Annals of the American Association of Geographers},
	author = {Nüst, Daniel and Pebesma, Edzer},
	month = oct,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/24694452.2020.1806028},
	keywords = {reproducible research, scholarly communication, computational reproducibility, comunicación erudita, investigación reproducible, reproducibilidad computacional, 可再现研究, 科学沟通, 计算可再现性},
	pages = {1--11},
	file = {Full Text PDF:/Users/jones/Zotero/storage/YBGFC9UT/Nüst and Pebesma - 2020 - Practical Reproducibility in Geography and Geoscie.pdf:application/pdf;Snapshot:/Users/jones/Zotero/storage/2VWBKEKN/24694452.2020.html:text/html},
}

@article{powers_open_2019,
	title = {Open science, reproducibility, and transparency in ecology},
	volume = {29},
	issn = {1939-5582},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/eap.1822},
	doi = {10.1002/eap.1822},
	abstract = {Reproducibility is a key tenet of the scientific process that dictates the reliability and generality of results and methods. The complexities of ecological observations and data present novel challenges in satisfying needs for reproducibility and also transparency. Ecological systems are dynamic and heterogeneous, interacting with numerous factors that sculpt natural history and that investigators cannot completely control. Observations may be highly dependent on spatial and temporal context, making them very difficult to reproduce, but computational reproducibility can still be achieved. Computational reproducibility often refers to the ability to produce equivalent analytical outcomes from the same data set using the same code and software as the original study. When coded workflows are shared, authors and editors provide transparency for readers and allow other researchers to build directly and efficiently on primary work. These qualities may be especially important in ecological applications that have important or controversial implications for science, management, and policy. Expectations for computational reproducibility and transparency are shifting rapidly in the sciences. In this work, we highlight many of the unique challenges for ecology along with practical guidelines for reproducibility and transparency, as ecologists continue to participate in the stewardship of critical environmental information and ensure that research methods demonstrate integrity.},
	language = {en},
	number = {1},
	urldate = {2021-07-01},
	journal = {Ecological Applications},
	author = {Powers, Stephen M. and Hampton, Stephanie E.},
	year = {2019},
	note = {\_eprint: https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1002/eap.1822},
	keywords = {workflows, reproducibility, open science, data science, collaborative tools, data policy, ecoinformatics, ecosystem, environmental science, repeatability, replicability, reproducible, transparent},
	pages = {e01822},
	file = {Full Text PDF:/Users/jones/Zotero/storage/FB74ZVZX/Powers and Hampton - 2019 - Open science, reproducibility, and transparency in.pdf:application/pdf;Snapshot:/Users/jones/Zotero/storage/XS95BXHS/eap.html:text/html},
}

@article{wilson_five-star_2021,
	title = {A {Five}-{Star} {Guide} for {Achieving} {Replicability} and {Reproducibility} {When} {Working} with {GIS} {Software} and {Algorithms}},
	volume = {111},
	issn = {2469-4452},
	url = {https://doi.org/10.1080/24694452.2020.1806026},
	doi = {10.1080/24694452.2020.1806026},
	abstract = {The availability and use of geographic information technologies and data for describing the patterns and processes operating on or near the Earth’s surface have grown substantially during the past fifty years. The number of geographic information systems software packages and algorithms has also grown quickly during this period, fueled by rapid advances in computing and the explosive growth in the availability of digital data describing specific phenomena. Geographic information scientists therefore increasingly find themselves choosing between multiple software suites and algorithms to execute specific analysis, modeling, and visualization tasks in environmental applications today. This is a major challenge because it is often difficult to assess the efficacy of the candidate software platforms and algorithms when used in specific applications and study areas, which often generate different results. The subtleties and issues that characterize the field of geomorphometry are used here to document the need for (1) theoretically based software and algorithms; (2) new methods for the collection of provenance information about the data and code along with application context knowledge; and (3) new protocols for distributing this information and knowledge along with the data and code. This article discusses the progress and enduring challenges connected with these outcomes.},
	number = {5},
	urldate = {2021-09-10},
	journal = {Annals of the American Association of Geographers},
	author = {Wilson, John P. and Butler, Kevin and Gao, Song and Hu, Yingjie and Li, Wenwen and Wright, Dawn J.},
	month = jul,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/24694452.2020.1806026},
	keywords = {reproducibility, replicability, application context knowledge, conocimiento del contexto de la aplicación, e-ciencia, e-science, GIS, replicabilidad, reproducibilidad, scientific workflow systems, SIG, sistemas de flujo de trabajo científico, 可再现性, 可重复性, 地理信息系统, 应用背景知识, 数字科学, 科学工作流程系统},
	pages = {1311--1317},
	file = {Full Text PDF:/Users/jones/Zotero/storage/4ZV8TGZJ/Wilson et al. - 2021 - A Five-Star Guide for Achieving Replicability and .pdf:application/pdf;Snapshot:/Users/jones/Zotero/storage/UGEW573A/24694452.2020.html:text/html},
}

@article{amaral_reproducibility_2021,
	title = {Reproducibility: expect less of the scientific paper},
	volume = {597},
	copyright = {2021 Nature},
	shorttitle = {Reproducibility},
	url = {https://www.nature.com/articles/d41586-021-02486-7},
	doi = {10.1038/d41586-021-02486-7},
	abstract = {Make science more reliable by placing the burden of replicability on the community, not on individual laboratories.},
	language = {en},
	number = {7876},
	urldate = {2021-09-19},
	journal = {Nature},
	author = {Amaral, Olavo B. and Neves, Kleber},
	month = sep,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Number: 7876
Publisher: Nature Publishing Group
Subject\_term: Publishing, Research data, Research management},
	pages = {329--331},
	file = {Full Text PDF:/Users/jones/Zotero/storage/Q3RNYHHK/Amaral and Neves - 2021 - Reproducibility expect less of the scientific pap.pdf:application/pdf;Snapshot:/Users/jones/Zotero/storage/U9BZFKVW/d41586-021-02486-7.html:text/html},
}
