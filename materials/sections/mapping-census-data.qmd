## Learning Objectives {.unnumbered}
-   Review how the `tidycensus` package works
-   Get acquaint on how spatial census data works 
-   Introduce tools to create static and interactive maps with census data


:::callout-note
## Acknowledgement
This lesson is heavily based on Kyle Walker's talk ["Mapping And Spatial Analysis with ACS data in R"](https://walker-data.com/umich-workshop-2023/spatial-data/#1) As part of the Census Data Workshops given at the University of Michigan in February 2023.
:::


## Census data with `tidycensus`
The `tidycensus` package (Walker and Matt (2021)) was developed to systematize the process of working with U.S Census data using R. 
It uses the Census Application Programming Interface (API) as a way to disseminate government data resources to the public. `tidycensus` incorporates the API release by the the U.S Census Bureau into an R package to facilitate access to census data using R.

`tidycensus` main functions:
-   `get_decennial()`
-   `get_acs()`
-   `get_estimates()`
-   `get_pums()`
-   `get_flows()`

The focus of this lesson will be mapping data from the American Community Survey (ACS), so we will mainly be using `get_acs()`

### American Community Survey (ACS) recap

<!--*FROM WALKERS SLIDES*-->
-   Annual survey of 3.5 million US households

-   Covers topics not available in decennial US Census data (e.g. income, education, language, housing characteristics)

-   Available as 1-year estimates (for geographies of population 65,000 and greater) and 5-year estimates (for geographies down to the block group)

-   2020 1-year data only available as experimental estimates
Data delivered as estimates characterized by margins of error

Important of 5y acs to access data of geographies with population less than 65K.


<!--_EXPLAIN HOW get ACS WORKS_
Talks about geographies and variables! -->

:::callout-warning
## Decennial Census 
Complete enumeration of the US population to assist with apportionment. It asks a limited set of questions on race, ethnicity, age, sex, and housing tenure. Data from 2000, 2010, available data from 2020
:::

#### How to access ACS data: `get_acs()`

One "simple" way to access the ACS data is using `tidycensus` `get_acs()` function. This function:

<!--*WALKER'S SLIDES*
-   "Wrangles Census data internally to return tidyverse-ready format (or traditional wide format if requested);"

-   "Includes tools for handling margins of error in the ACS and working with survey weights in the ACS PUMS;"

-   "States and counties can be requested by name (no more looking up FIPS codes!)"

AND..

-   "Automatically downloads and merges Census geometries to data for mapping." -->


`Tidycensus` streamlines the process of working with ACS data
(`tidycensus` does all this for you!)

This packages get the data for you, it shapes it in a format ready to go for analysis following the "tidy" principles, it pre joins the census geometries this means you get your data and spatial data automatically. And is streamlines the process of doing target requests.


<!-- MENTION SOMTHING ON NECESARY INFORMATION  AND VAIRIABLE CODES!-->

## Spatial Census Data in `tidycensus`

<!--*From Walkers book*-->

"Traditionally, getting “spatial” Census data requires a tedious multi-step process that can involve several software platforms. These steps include:

Fetching shapefiles from the Census website;

Downloading a CSV of data, then cleaning and formatting it;

Loading geometries and data into your desktop GIS of choice;

Aligning key fields in your desktop GIS and joining your data."


### Spatial Census data with `get_acs()`

```{r}
#| warning: false
#| message: false

library(tidycensus)
library(mapview)
library(tigris)
library(ggplot2)
library(dplyr)
library(sf)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}

census_api_key("4f556c250dfa5332ac1d4b0848049c4959844b80", 
               overwrite = TRUE)
```



When working with spatial data, the 5 year estimate data will be more of interest because spatial analysis often involved small area analysis and we don't have all the information in the 1-year ACS for those small areas (65 thousand and under.)


```{r}
#| warning: false
#| message: false
#| results: hide

## defaults to most recent 5year estimates (2017-2021 5-year ACS)
ca_income <- get_acs(
    geography = "county",
    variables = "B19013_001",
    state = "CA",
    year = 2021,
    geometry = TRUE) ## This argument does everything we mentioned above.

```

And that's it!! Now we have the corresponding spatial data bind to our variable of interest. We can plot this data using the base r `plot()` function.


```{r}
plot(ca_income["estimate"])
```

Now we have our data ready to start exploring!

### What's under the hood
 `sf` package. We learned during week 2 about this package. 
 
<!-- _WALKER'S SLIDES_-->
-   The sf package implements a simple features data model for vector spatial data in R

-   Vector geometries: points, lines, and polygons stored in a list-column of a data frame.

Allows the R community to work with spatial data just like you work with any other type of data, in a tabular format.

Let's take a look at our data

```{r}
head(ca_income)
```

We can see that this is a Simple feature collection with 6 features and 5 fields. For those of you familiar with GIS, probably this is known terminology. But for those of you that this is all new, you can think of a feature like a simple shape on your data layer. Generally in a GIS perspective feature means a row in the data. In this case for example, Ventura County is a county and the shape of that county iy self is a feature. And then a field in GIS terminology means an attribute of the data or a column.

Similar how we saw last time in the Spatial Data lesson, we have a `geometry` column. This contains all the spatial information

geometry column of multipolygons. A polygon is a two dimensional shape, it has a perimeter and an area. A multipolygon are multiple shapes that belong to the same feature. For example if we have census data for the state of Hawaii, we will have multiple polygon, one for each island, representing that row or feature.

We also can se the CRS associated to this data and the bounding box that indicated the extension of our data set.

<!--_Add note on CRS_ --> Coordinate Reference System, how are the coordinates in our polygons referenced to the earth surface. It handles how the mapping of our data to the actual earth.-->

And then we have the data it self. `GEOID`, `NAME`, `estimate` and `moe` (margin of error) (interpreted at 90% confidence level)

:::callout-warning
## Note on missng data
Remember that 5 year ACS data are projections from a sample. Counties with no data means that the population in those counties is not large enough to make these projections.
:::

### Adding interactivity

For a lot of GIS users it is hard to transition from GIS to working with spatial data in R because GIS provides nice interactive tools. One easy way to make your R maps interactive is the `mapview()` package. This package wraps up different interactive mapping tools and allows you to explore your data just by running a single line of code. Let's try this.

```{r}
mapview(ca_income, zcol = "estimate")
```


The `zcol =` argument, allows us to easily plot data to this interactive map. We can explore the data using the RStudio Viewer.


Let's look at another example at a smaller census geography. `tidycensus` is really helpful to look at spatial data in smaller geography.

```{r}
#| warning: false
#| message: false
#| results: hide


solano_income <- get_acs(
    geography = "tract",
    variables = "B19013_001",
    state = "CA",
    county = "Solano",
    geometry = "TRUE")

head(solano_income)
```

We can again use `mapview()` to check out our data.

```{r}
mapview(solano_income, zcol = "estimate")
```

With these two packages we can almost instantly explore different data from the ACS surveys. Note that for census tracts, the MOE will be much higher than for county data.

### Spatial data structure in `tidycensus` (long versus wide)

The default of `tidycensus` is to return a data frame in a "long" format. This is generally the preferred way to work and analyze data in R. But, if you rather have a "wide" data frame as the output (GIS users are generally used to wide format) you can do that by adding the argument `output = wide`. This will return a data frame where each variable is in a different column. For example:

```{r, warning=TRUE, message=FALSE}


race_var <- c(
    Hispanic = "DP05_0071P",
    White = "DP05_0077P",
    Black = "DP05_0078P",
    Asian = "DP05_0080P")

## Default long
alameda_race <- get_acs(
  geography = "tract",
  variables = race_var,
  state = "CA",
  county = "Alameda",
  geometry = TRUE)

head(alameda_race)


```

And now in wide format. Every variable (Hispanic, White, Black and Asian) is in a different column as opposed to being stacked into one column named variable.

```{r, warning=FALSE, message=FALSE}

alameda_race_wide <- get_acs(
  geography = "tract",
  variables = race_var,
  state = "CA",
  county = "Alameda",
  geometry = TRUE,
  output = "wide")

head(alameda_race_wide)
```

Both data frames `alameda_race` and `alameda_race_wide` have the same exact information. They are just in a different shape. Depending on what are you want to do with the data which one you should retrieve. 


## Working with Census Geometry

<!--_FROM SLIDES_-->

-   `tidycensus` uses the `tigris` R package internally to acquire Census shapefiles

-   By default, the Cartographic Boundary shapefiles are used, which are pre-clipped to the US shoreline

-   `tigris` offers a number of features to help with acquisition and display of spatial ACS data. Making your work with ACS data better.
 
<!--_ADD MORE FROM BOOK_ (Go into projections??)

_ADD HEX IMAGE ON THE SIDE_ -->

Let's go back to our map of Solano County.


```{r, warning=FALSE, message=FALSE}
solano_income <- get_acs(
    geography = "tract",
    variables = "B19013_001",
    state = "CA",
    county = "Solano",
    geometry = "TRUE")

mapview(solano_income, zcol = "estimate")
```

We can see that there are some issues with the interior water areas. They are often not removed from the Cartographic Boundary shapefiles. What can we do about it? We can again leverage on how powerful these tools are on making complex process simple.

There is a function in the `tigris` package that "erase water"! It finds water areas in a shapefile and removes those water areas, giving you a result that allows you to better display your data. Let's take a look on how this works.

```{r, warning=FALSE, message=FALSE}

sf_use_s2(FALSE) ## Need to run this so that mapview works.

solano_erase <- erase_water(solano_income,
                            area_threshold = 0.9,
                            year = 2021)

mapview(solano_erase, zcol = "estimate")

```

And just like that! We get a much more accurate map of Solano County.

## Mapping ACS data

There are a several extraordinary packages in R to visualize cartographic data. Today we are going to be using our good good friend `ggplot2`. In the last section of this lesson you can find resources to other cartography mapping packages like `tmap`.

There is a reason why we have over and over used `ggplot2` throughout the lessons in this course. It is a very powerful data visualization tool! In fact, is one of the most downloaded packages in R. And, as we learned in the "working with spatial data" lesson, there is a function called `geom_sf()` that allows us to easily plot spatial data.

How do we plot ACS data using ggplot?

Lets make a map with the Hispanic population in Alameda County by Census tract.

Se we are going to use the `alameda_race` object we created earlier. And we are going to start by filtering the data for Hispanic population.

```{r}
alameda_hispanic <- filter(alameda_race,
                           variable == "Hispanic")

ggplot(alameda_hispanic,
       aes(fill = estimate))+
    geom_sf() ## plots polygons!

```

Here we have our choropleth map with the Hispanic population in Alameda County! A choropleth plot provides a shade or color to a polygon (or shape) according to a giving attribute.

Here we are mapping the estimate column to the fill of whatever shape I'm plotting in this case the tract polygon. The geom_sf() plots polygons!


A choropleth is a map that uses shading to show variation in some sort of data attribute.
In this case, the lighter colors represent higher values, this means that tract with lighter shades of blue have higher Hispanic population. And the darker ares represent the lower values, fewer presence of Hispanic/Latino population.

As we know, with `ggplot2` we can heavily style out plot. Here an example of customization.

```{r}
ggplot(alameda_hispanic, aes(fill = estimate)) + 
  geom_sf() + 
  theme_void() + 
  scale_fill_viridis_c(option = "rocket") + 
  labs(title = "Percent Hispanic by Census tract",
       subtitle = "Alameda County, California",
       fill = "ACS estimate",
       caption = "2017-2021 ACS | tidycensus R package")
```

You can also plot you data in binds.

```{r}
ggplot(alameda_hispanic, aes(fill = estimate)) + 
  geom_sf() + 
  theme_void() + 
  scale_fill_viridis_b(option = "rocket", n.breaks = 6) + 
  labs(title = "Percent Hispanic by Census tract",
       subtitle = "Alameda County, California",
       fill = "ACS estimate",
       caption = "2017-2021 ACS | tidycensus R package")
```

Which one to use Depends on what you want to achieve. We can see that in the plot with bins we loose some resolution. On the other hand the continuous scale can provide a little of a color over load.

We can keep leveraging on `ggplot2` power and plot more variables of our data.

```{r}
ggplot(alameda_race, aes(fill = estimate)) + 
  geom_sf(color = NA) + 
  theme_void() + 
  scale_fill_viridis_c(option = "rocket") + 
  facet_wrap(~variable) +
  labs(title = "Race / ethnicity by Census tract",
       subtitle = "Alameda County, California",
       fill = "ACS estimate (%)",
       caption = "2017-2021 ACS | tidycensus R package")
```

Explanation of pro and cons to this approach (1:25:40)

### Mapping Count Data

So far we have been mapping percentage. But what if your data is not percentage but count? Choropleth are great for mapping ratios and percentage, but not so great for mapping counts. When you are working with count data, you wanna have some way to represent the extent of the count through symbols. We are going to show this with an example.

We start by getting the count data for race/etnicity. Note that the process is practically the same that we did above, but there is a slight difference in the varaible codes we are going to use. Generally, variables that end in "P" means the estimate is in percentage. Variable with out the "P" at the end are count data.

<!--FROM slides:
At times, you'll want to show variations in counts rather than rates on your maps of ACS data

Choropleth maps are poorly suited for count data

Let's grab some count data for race / ethnicity and consider some alternatives -->


```{r, message=FALSE, warning=FALSE}
alameda_race_counts <- get_acs(
  geography = "tract",
  variables = c(
    Hispanic = "DP05_0071",
    White = "DP05_0077",
    Black = "DP05_0078",
    Asian = "DP05_0080"
  ),
  state = "CA",
  county = "Alameda",
  geometry = TRUE
)

## Checking our data. Estimates are in counts not in %
head(alameda_race_counts)

```

The first map we are going to plot is a *graduate symbol map*. This kind of maps are good for count data because the comparison we are making are between symbols of the same shape. The size of the symbol is proportional to the underlying data value. The most common shape to use for this kind of plots are circles.

The tricky thing here, and this also speaks to really understanding our data and what we are trying to plot, is that our data is represented as polygons and we want to map points or circle. So we need to convert our data from polygons to circle.

As a reminder, polygons are closed shapes with a perimeter and an area. We have to convert this shape to a single point and draw a circle proportional to the corresponding data value.

There is a function from the `sf` package that allows us to do this. This function is `st_centroid()`. This function converts a shape, for example the shape of a census tract to a point, right in the center of that tract. So lets convert part of our Alameda race data to centroids. We are going to filter for the Asian population.

```{r}
alameda_asian <- alameda_race_counts %>% 
    filter(variable == "Asian")


centroids <- st_centroid(alameda_asian)

```

:::callout-warning
## Warning message:
`st_centroid assumes attributes are constant over geometries`

This message is letting us know that you are converting a polygon to a single point, and this point might not truly represent where people in this tract live.
Just a heads up of what is happening.
:::

Now we can plot.

```{r}
ggplot() + 
  geom_sf(data = alameda_asian, color = "black", fill = "lightgrey") + 
  geom_sf(data = centroids, aes(size = estimate),
          alpha = 0.7, color = "navy") + 
  theme_void() + 
  labs(title = "Asian population by Census tract",
       subtitle = "2017-2021 ACS, Alameda County, California",
       size = "ACS estimate") + 
  scale_size_area(max_size = 6)
```

`scale_size_area()` argument makes the area of the cirles proportional. In this case the area representing 2500 is about half of the area of the 5000 circle. Overall, areas with smaller circles are areas with less non-Hispanic Asian population and areas with larger circles have a larger Asian population. This kind of maps makes it easer to visualize change across the different area. For example, larger counts with a very low Asian population are represented with a small circle instead of painting the whole are with a color that represents a low population.

We can compere location of a point and size according to the estimated value of the population.

Another way of plotting count data is with a *dot-density map*. This kind of maps excel at plotting multiple variables in one map. On the previews plot we were able to plot the Asian population and clearly see how it changes among census tract. However, the graduate symbol map doesn't really allow as to to plot heterogeneity, or the mixing of different racial groups in this case. For example to see how different groups live together.

<!-- FROM SLIDES
It can be difficult to show heterogeneity or mixing of different categories on maps

Dot-density maps scatter dots proportionally to data size; dots can be colored to show mixing of categories

Traditionally, dot-density maps are slow to make in R; tidycensus's as_dot_density() function addresses this -->

`as_dot_density()` function allows you to calculate these density dots based on your data. It is design for categorical mapping of ACS and Census data. It takes in data in a long format

values_per_dot = dot to data ratio, how many data points does each dot represent. In this case `values_per_dot = 200` means that each dot represents 200 people.

`group =` is an argument that allow as to group out data. In this case `group = "variable"` groups the data by each of the categories in the `variable` column and creates a dot for each of those categories.



```{r}
alameda_race_dots <- as_dot_density(
  alameda_race_counts,
  value = "estimate",
  values_per_dot = 200,
  group = "variable"
)
```

There are a lot of calculations happening under the hood here. What this function is doing is scattering dots with each census tract proportional to the number of people that are in each group (in this case groups are defined by the categories in the variable column).

Let's look at the outcome data. We can already see that this data frame has many more rows than our input data. This is because, each row in this case just represents up to 200 people, as we defined in the `values_per_dot` argument.
We can also see that we have a geometry type POINT.

```{r}
head(alameda_race_dots)
```

Now we can plot this data using the same workflow than our previews map.

```{r}
ggplot() + 
  geom_sf(data = alameda_race_counts, color = "lightgrey", fill = "white") + 
  geom_sf(data = alameda_race_dots, aes(color = variable), size = 0.5, alpha = 0.5) +
  scale_color_brewer(palette = "Set2") + 
  guides(color = guide_legend(override.aes = list(size = 3))) + ## overrides the size of the dots in the legend to make it more visible
  theme_void() + 
  labs(color = "Race / Ethnicity",
       caption = "2017-2021 ACS | 1 dot = approximately 200 people")
```

This are some of the examples of plotting census data or ACS in this case using static maps.


### Interactive maps

- Customizing map view
- sync two interactive maps

For side-by-side exploratory mapping. This way you can explore your data in a very exhaustive way.

<!--- something about leaflet??-->

<!-- ggiraph! maybe demo with Walkers book-->
<!--- sync a plot with a map!-->



## Resources
- mention `tmap`
- mention maps and shiny
- mention segregation analysis

## Practice







