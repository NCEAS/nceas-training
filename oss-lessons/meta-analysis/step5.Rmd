---
title: 
author: "cjlortie"
date: "2017"
output:
  html_document:
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
   
---

<br>
![](./statistics.jpg)     
<br>

###Step 5. Statistics  
The field of meta-statistics is a rich and fascinating set of tools, literature, and discussions. Herein, we direct the practioner to several extremely useful resources associated with this specific topic. To become competent with an open science worflow for meta-analysis, a detailed knowledge of the statistics is of course preferable but not critical. A viable philosophy for the appropriate application of meta-statistics is best defined by the following set of assumptions. (1) Know thy 'derived' data and the limitations of the set of research summarized. This informs the statistics. (2) All statistics are a tool and a means to end - not the end. (3) The formal application of statistics to data from the t-test to the most advanced analysis you can imagine is an exercise in model fitting. A model is a representation of an idea. Period. Statistics are thus one mechanism that provides the evidence-based synthesis researcher with a tool to represent the ideas that stimulated the synthesis. No more, no less. (4) Description of the patterns across a set of studies or datasets is a powerful discovery tool. Do not underestimate the power of... this side of synthesis (or the force). (5) A meta-analysis is not an experiment and does not directly test a hypothesis. It can provide quantitative evidence and probabilities associed with strength of evidence, differences, and consistency and establish a weighted description of the efficacy of different interventions very broadly. (6) Even more profoundly and not uncommonly, meta-analysis as an open science synthesis research tool can highlight research gaps. (7) An ideal starting point is to assume that simple meta-statistics are akin to an ANOVA but for a population of relatively-independent singular data points. This constellation of points can be modeled as fixed or random. More advanced meta-analyses or differences in the type of data simply shift the perspective from ANOVA to reframing as a GLM (same thing) but then slides along to GLMM and this broader family of thinking. Not dissimilar from primary data statistical thinking. The difference is that we do not have one 'data' but 'many representative data'. Very Seussian. There are four primary processes associated with the statistics step of an open science approach to meta-analysis.  

**Key meta-statistical processes**
(a) calculate effect size(s)  
(b) visualize effect size data (typically a forest plot)  
(c) fit a meta-statistical model  
(d) explore heterogeneity and bias  

###Open science product  
A [forest plot](https://en.wikipedia.org/wiki/Forest_plot) is typically the primary open science research product and assumed to be included in some form within the synthesis publication as a key figure. Ideally, contemporary open science researcher should also publicly and openly disseminate the statistical workflow - i.e. share R code illuminating this element of the workflow and ensuring the meta-statistics like the search and sort processes are reproducible.  

###Case study  
The book [Meta-analysis with R](http://www.springer.com/us/book/9783319214153) provides an extensive set of worked examples including data and R code. The packages 'meta' and 'metafor' are also bundled with sample datasets. To promote continuity, here are some of the examples from previous steps provided as an indication of the ease of meta-analysis with R. It is not the implementation of the code that limits us in doing meta-analyses but the access to data. The package meta (and metafor) provide most meta-statistical options as functions or arguments within broader functions for all the data differences and data structures that an environmental or natural science reseacher will encounter.

The pattern of steps you will see below in code chunk include the following:

data (read in and tidy up as needed)
assign meta-model to object
viz
examine model
heterogeneity
bias
sensitivity


```{r statistical model fitting, warning=FALSE, message=FALSE, fig.width=12, fig.height=12}
#library setup####
library(tidyverse)
library(plotrix) #for quick s.e. calculations sometimes needed for data tidy step
library(meta) #nice package for most meta-statistics

#installation as needed
#pkgs <- c("mada", "meta", "metafor", "metasens", "mvmeta", "netmeta", "rmeta", "ellipse") #recommended install for almost every meta-challenge you will encounter, most parsonimous install is 'meta'
#install.packages(pkgs, repos="http://cran.rstudio.com/") #run once per machine not per instance

#R-STEPS REMINDERRRR####
#data
#assign model
#viz
#examine model
#heterogeneity
#bias
#sensitivity

#CASE 1. Effect sizes####
#if reported within primary studies, you could be ready to go already. If not, the package meta provides a wide variety of standard effect size measures provided you have the data.

#data (read, tidy, and structure as needed)
cushions <-read_csv("data/cushion-data.csv") #dataset that captured effect sizes directly from plant interaction studies
data <- cushions %>% group_by(Study) %>% summarise(mean.Rii = mean(Rii), error = std.error(Rii))

#assign model (typically a nice meta. function from one of several packages such as meta, metafor, or netmeta)
m <- metagen(mean.Rii, error, studlab = Study, data = data) #fit generic meta-analysis to an object

#viz (draw a standard forest plot or metaregression plot)
forest(m) #grid-based graphics so a bit of work to resize

#examine model (print meta-statistical model you fit)
m #By default, the DerSimonian-Laird estimate (1986) is used in the random effects model (method.tau="DL"), however this argument change be changed to the statistical norm for your field or specific data. another popular method in ecology is the Restricted maximum-likelihood estimator (method.tau="REML")

#heterogeneity (inspect above model Qstats)
#This is listed in model output. From 'meta-analysis with r' book for the 'meta' package for instance, Q is the weighted sum of squares about the fixed effect estimate. Large values of Q indicate greater heterogeneity between the individual studies in a meta-analysis, and greater values of the between-study heterogeneity. If p < 0.05, there is 'significant' heterogeneity from study-to-study. Nonetheless in this context, you must contrast the fixed versus random-effects models and the sign of the study-level effect sizes measures to conclude whether the treatment is effective and/or consistent.  

#bias (explore)
funnel(m) #plot to explore distribution of sign and magnitude of the effect size measures, asymmetry suggests bias in the field of research
metabias(m, method="rank") #if p < 0.05, there is likely plot asymmetry
radial(m) #also an excellent means to qualitatively explore bias but explores the variance associated with effect sizes
metabias(m, method = "linreg") # nice quick check of bias but inspecting residuals is more powerful
#the Rosenthalâ€™s fail-safe number is also sometimes reported in the literature and can be calculated using metafor::fsn
#test sensitivity of the effect size measure
#contrast the fixed versus random effect model
#test the importance of the subgroups -- typically this is the MOST important test for bias - sensitivity

#sensitivity (critical step)
#subgroups we could explore include elevation and the measure used to estimate the effect of this potential keystone species
#elevation cofactor/subgroup
data <- cushions %>% group_by(Study, elevation) %>% summarise(mean.Rii = mean(Rii), error = std.error(Rii))
m <- metagen(mean.Rii, error, studlab = Study, byvar = elevation, data = data)
#viz
forest(m) 
#model
m
#heterogeneity
#inspect heterogeneity now using between AND within groups - very important
#bias is being explored using the byvar argument
#funnel(m) #same as whole model plot

#measure cofactor/subgroup
data <- cushions %>% group_by(Study, measure) %>% summarise(mean.Rii = mean(Rii), error = std.error(Rii))
m <- metagen(mean.Rii, error, studlab = Study, byvar = measure, data = data) #fit generic meta-analysis to an object
forest(m, sortvar=measure) 
#viz
forest(m) 
#model
m
#heterogeneity
#inspect heterogeneity now using between AND within groups - very important
#bias epxlored via the byvar argument
#funnel(m) #same as whole model plot

#and yes, you can do meta-statistics like a GLM with interaction terms and also predictions
#also if data structure and the dataframe are consistent, doing sensitivity analyses can be very rapid using the 'update' global function in R
#there is also a 'metareg' function in the meta package do meta-regression if for instance you test elevation in this example using actual elevation of each study in m and not as a category

#One more quick example to highlight the ease of meta-statistics in R

#CASE 2. Continuous response data
#Revisit dune meta-analysis example

#data
dunes.data <- read_csv("data/dune-growthLRR.csv")

#assign model
m <- metacont(Ne, MEANe, SDe, Nc, MEANc, SDc, studlab = study, data=dunes.data)#metacont is used for continuous data with arguments in this order within call metacont(n.e, mean.e, sd.e, n.c, mean.c, sd.c, studlab = study, data=data)

#viz
forest(m)

#model
m

#heterogeneity
#inspect main model heterogeneity if statistically significant one needs to identify source (i.e. cofactors or subgroups)

#bias
funnel(m)
metabias(m, method="rank") #if p < 0.05, there is likely plot asymmetry
radial(m) #also an excellent means to qualitatively explore bias but explores the variance associated with effect sizes
metabias(m, method = "linreg")

#sensitivity (bias and heterogeneity)
#in this example, region where the dune study was done is likely an important source of heterogeneity

#data
#no need to wrangle

#assign model
m <- update(m, byvar = Region) #use update

#viz
forest(m)

#model
m

#sensitivity
#interpret within versus between heterogeneity and the byvar effect size patterns

```

###Exercise  
Install then load 'meta' package. Work through one generic example using data within the package, from this repo, or from the resource site for the "Meta-analysis with R" book that provides many meta-datasets. Then, use your existing synthesis dataframe, generate an rmarkdown file and work through the basic meta-statistical steps listed above.

###Conclusions
1. There is a global open science workflow for scientific synthesis that culminates with a systematic review or meta-analysis.  
2. There are several clear steps within the meta-statistics step of this larger worflow.  
3. The meta-statistical workflow is just as important as the statistics.  
4. Herein, only the briefest tour of a single package and some function/argument opportunities are shown. There is an immense set of tools available within the contemporary R community for meta-analyses.  
5. This workflow and parsimonous set of steps to meta-statistics provides a reasonable and balanced approach to interpreting the strength of evidence for a set of studies/datasets and can highlight research gaps. More detailed statistics and tests are available but this approach encompasses 95% of of the synthesis studies currently published within the natural sciences.

###Additional resources  
[Meta-analysis with R](http://www.springer.com/us/book/9783319214153) is a stunning resource.  

The [meta](https://cran.r-project.org/web/packages/meta/index.html) vignette is an excellent starting point for an overview of the functions and data in this package.

The [metafor](https://cran.r-project.org/web/packages/metafor/index.html) resources provided by CRAN are similarly useful.

There are many 'how-to' papers published for meta-analysis. [Here](http://onlinelibrary.wiley.com/wol1/doi/10.1348/000711010X502733/full) is nice example.

['forestplot'](https://cran.r-project.org/web/packages/forestplot/forestplot.pdf) is also a nice, well-supported CRAN alt-viz option.

[summary of forest tweaks from meta package](https://rdrr.io/cran/meta/man/forest.html)