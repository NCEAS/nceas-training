---
title: "SQL Database Access in R"
time_slot: 60 minutes
---

## Introduction

Continuing on from our earlier lesson on SQL, we're going to learn how to work with SQL and database in R.
There are two ways we're going to go over:

1. Directly executing SQL statements against a database
2. Using `dplyr`'s seamless ability to work with SQL databases

## Learning outcomes

Students should:

- Be able to connect to an SQL database in R
- Be able to load external data in CSV format into a table in the database
- Be able to run a query against a database table in R
- Be able to run an SQL join against two database tables in R
- Become familiar with connecting `dplyr` to a database

## Lesson

### Work with SQL directly using the `DBI` package

This content is largely adapted from the [DBI homepage](http://rstats-db.github.io/DBI/).

Before we can query a database for information, we have to connect to it.
In the chunk below, we connect to a temporary, in-memory database.

```{r}
library(DBI)
con <- dbConnect(RSQLite::SQLite(), dbname = ":memory:")
```

The above command creates an empty database with no tables.
We can confirm this is the case with `dbListTables()`:

```{r}
dbListTables(con)
```

Before we can do any useful querying, we need to load data into our database.
Let's load a `data.frame` into a table:

```{r}
dbWriteTable(con, "mtcars", mtcars)
dbListTables(con)
```

We can immediately inspect what we just loaded like this:

```{r}
dbListFields(con, "mtcars")
dbReadTable(con, "mtcars")
```

Running queries is pretty simple:

```{r}
dbGetQuery(con, "SELECT * FROM mtcars WHERE cyl = 4")
```

Often times, when working with database, we won't want to see all of the rows because there are just too many to store in memory.
In fact, that's often the point of using the database in the first place.

The `DBI` package lets us iterate through the rows in groups of our choosing so that memory usage stays low:

```{r}
res <- dbSendQuery(con, "SELECT * FROM mtcars WHERE cyl = 4")

while (!dbHasCompleted(res)) {
  chunk <- dbFetch(res, n = 5)
  print(nrow(chunk))
}

dbClearResult(res)
```

Notice the output: 5, 5, 1.
Since we specified `n = 5` in `dbFetch`, we get new rows in chunks of 5.

After we're done, our script should close its connection:

```{r}
dbDisconnect(con)
```

That's the approach you'll use.

**Exercise**: DBI and starwars

Instructions: Load the starwars dataset from the `dplyr` package into an in-memory SQLite database and execute a query against the table.

e.g. list just the Droids

```{r}
library(DBI)
library(dplyr)
con <- dbConnect(RSQLite::SQLite(), dbname = ":memory:")
dbWriteTable(con, "starwars", select(starwars, -films, -vehicles, -starships))
             
# Your code here

```

### Automatic SQL with dplyr

`dplyr` is already an amazing tool for analyzing data.
But when we use it we're usually using it against a `data.frame` (or something similar).
Because it's *awesome*, `dplyr` also supports working directly with database tables as if they were regular old `data.frame`s.

All we have to do is use the `tbl` instead of, for example, our `read.csv` function call:

```{r}
# Set up an SQLite database again, as before
library(dplyr)
library(dbplyr)
library(DBI)

con <- dbConnect(RSQLite::SQLite(), dbname = ":memory:")
dbWriteTable(con, "mtcars", mtcars)

# Now the real magic
mtcars_db <- tbl(con, "mtcars")
mtcars_db

mtcars_db %>% 
  select(mpg) %>% 
  show_query()

mpg_query <- mtcars_db %>% 
  group_by(cyl) %>% 
  summarize(mean(mpg))

mpg_query %>% 
  show_query()

# To get the data out of our query, we use collect()
class(mpg_query)
mpg_query %>% 
  collect() %>% 
  class()
```

There, that's it.
`dbplyr` automatically converts our `dplyr` code into SQL queries behind the scenes and we get to use the usual `dplyr` functionality.
Awesome!

***Exercise: Connect to the SQLite database at `/home/mecum/oss/ramlegacy.db` on Aurora and calculate:

- Mean catch by stock ID
- Start and end year of each assessment

```{r, eval=FALSE}
library(dplyr)
library(dbplyr)
library(DBI)

con <- dbConnect(RSQLite::SQLite(), "/home/mecum/oss/ramlegacy.db")
dbListTables(con)

# Mean catch per stock
# Your code here

# Time range of assessment per stock
# Your code here
```

### Accessing an Microsoft Access database in R

Working with Microsoft Access databases in R is notoriously tricky.
As far as I can tell, the only way to make it work is to be running 32-bit Windows.
Most people are not running 32-bit Windows.

If you are, the basic incantation is:

```{r, eval=FALSE}
install.packages('RODBC')
library(RODBC)
db <- odbcConnectAccess("yourAccessDB.db")
```

And then you can send queries with `odbcQuery()`

## Summary

- Using SQL via R only requires a couple of lines of code
- We can use `dplyr` against an SQL database for intuitive querying that is fast

## Solutions

```{r, eval=FALSE}
library(DBI)
library(dplyr)
con <- dbConnect(RSQLite::SQLite(), dbname = ":memory:")
dbWriteTable(con, "starwars", select(starwars, -films, -vehicles, -starships))

dbGetQuery(con, "SELECT * FROM starwars WHERE species = 'Droid'")

dbDisconnect(con)
```

```{r, eval=FALSE}
library(dplyr)
library(dbplyr)
library(DBI)

con <- dbConnect(RSQLite::SQLite(), "/home/mecum/oss/ramlegacy.db")
dbListTables(con)

assessments <- tbl(con, "assessments")
timeseries <- tbl(con, "timeseries")

# Mean catch per stock
left_join(timeseries, assessments, "stockid") %>% 
  group_by(stockid) %>% 
  summarise(meanvalue = mean(tsvalue))

# Time range of assessment per stock
left_join(timeseries, assessments, "stockid") %>% 
  group_by(stockid) %>% 
  summarise(year_start = min(tsyear),
            year_end = max(tsyear))
```