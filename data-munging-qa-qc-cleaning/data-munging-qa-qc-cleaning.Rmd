---
title: "Data Munging / QA / QC / Cleaning"
time_slot: 60 minutes
---

## Introduction

## Leaning outcomes

Students should

- Learn what it means to test assumptions about their data (assertr)
- Learn how to reshape and restructure their data (tidyr)
- Be introduced to the `assertr` package for analysis QA

## Lesson

Let's look at an example dataset (one I've made).
It is an arbitrary temperature study with six sites. Within each site, there are 6 plots and we took 10 samples of temperature (degrees C) per plot.


```{r}
fundata <- read.csv("fundata.csv", stringsAsFactors = FALSE)
head(fundata)
```

Data often comes with columns mashed together which can prevent us from doing the exact analysis we want.
For example, in this dataset, the `siteplot` column is really two variables: Site and plot number.
How can we split them apart?

```{r}
library(tidyr)

lettersdf <- data.frame(letters = paste(LETTERS, rev(LETTERS), sep = "."))
lettersdf
lettersdf %>%
  separate(letters, c("letter_one", "letter_two"), sep = "\\.")
```

**Exercise:** Split the `siteplot` column into two columns called `site` and `plot`:

```{r}
# Your code here
```

### Checking assumptions

#### site & plot

Let's start by looking at the `site` column for issues.
The `table` function is a great way tally the occurrence of each of the unique values in a vector:

```{r}
table(fundata$site)
```

We can see we're missing some observations from A, C, and E.
And there's even an NA.
Depending on our needs, we may need to go back to our field notes to find out what happened.
For this mock analysis, let's remove the row with the `NA` for `site`:

**Exercise:** Remove the row with the `NA` as a value for `site`

```{r}
# Your code here
```

#### temp_c

Look with `summary`:

```{r}
summary(fundata)
```

Look directly with `range`:

```{r}
range(fundata$temp_c)
```

**Exercise:** Can we use an exploratory plot to check this assumption too?

Plotting your data is always a good idea and we can often find new insights or issues this way.

```{r}
# Your code here
```

Before we move on, let's fix the -9999 and 180 observations by making them `NA`s:

```{r}
fundata[which(fundata$temp_c == -9999), "temp_c"] <- NA
fundata[which(fundata$temp_c == 180), "temp_c"] <- NA
```

### Check for duplicate or missing observations

Since have a hierarchical design, we might want to check that all the data we expect are present.
If we know we have 6 sites with 6 plots at each site and ten samples, we can check this assumption a few ways:

```{r}
nrow(fundata) == 6 * 6 * 10
```

**Exercise:** Use `dplyr` to find which `site` or `plot` has the wrong number of observations

```{r}
# Put your solution here
```

**Exercise:** Check if any droids have hair or gender

```{r}
library(dplyr)
head(starwars)
```

**Exercise:** Make sure every character has been in at least one film

```{r}
```

### unique and duplicated

The functions `unique` and `duplicated` great ways to find duplicates in a vector of values.
For example, we can create a vector with a duplicate value in it:

```{r}
some_letters <- c("A", "F", "X", "S", "X")
some_letters
```

```{r}
length(unique(some_letters)) == length(some_letters)
duplicated(some_letters)
```

See how `unique` can tell us *if* there are duplicates and `duplicated` can tell us *which* values are duplicates?

**Exercise:** Remove the duplicate value with `unique` and with `duplicated`:

```{r}
# Your code here
```

### more `tidyr`

We already saw how separate and how useful it can be. 
`tidyr` provides two other functions I use all the time: `gather` and `spread`.

#### `gather`

`gather` takes our data that is *wide* (multiple observations on each row) and puts it into a *tall* form where each row is an observation.

```{r}
# Make some 'wide' data first
x <- data.frame(site = c("A", "B", "C"),
                width = runif(3, 2, 10),
                height = runif(3, 40, 80))
x

# Gather it
y <- gather(x, var, val, -site)
y
```


#### `spread`

`spread` does the opposite:

```{r}
y %>% spread(var, val)
```


### The `assertr` package approach

> The assertr package supplies a suite of functions designed to verify assumptions about data early in an analysis pipeline so that data errors are spotted early and can be addressed quickly.

- Website: https://github.com/ropensci/assertr

The basic idea is that we should check qualities of our dataset prior to analysis and that we can actually make the analysis not run if certain assertions are not met.

```{r}
library(assertr)

mtcars %>% verify(TRUE) %>% nrow(.)
mtcars %>% verify(FALSE) %>% nrow(.)
```

Let's walk through the introduction taken from the [README](https://github.com/ropensci/assertr):

Let's work with the `mtcars` dataset.
We don't know who created it and, in order to do an analysis with it, we might want to check a few assumptions:

- that it has the columns "mpg", "vs", and "am"
- that the dataset contains more than 10 observations
- that the column for 'miles per gallon' (mpg) is a positive number
- that the column for ‘miles per gallon’ (mpg) does not contain a datum that is outside 4 standard - deviations from its mean, and
- that the am and vs columns (automatic/manual and v/straight engine, respectively) contain 0s and 1s only
- each row contains at most 2 NAs
- each row is unique jointly between the "mpg", "am", and "wt" columns
- each row's mahalanobis distance is within 10 median absolute deviations of all the distances (for outlier detection)

This could be written (in order) using assertr like this:

```{r}
library(dplyr)
library(assertr)

mtcars %>%
  verify(has_all_names("mpg", "vs", "am", "wt")) %>%
  verify(nrow(.) > 10) %>%
  verify(mpg > 0) %>%
  insist(within_n_sds(4), mpg) %>%
  assert(in_set(0,1), am, vs) %>%
  assert_rows(num_row_NAs, within_bounds(0,2), everything()) %>%
  assert_rows(col_concat, is_uniq, mpg, am, wt) %>%
  insist_rows(maha_dist, within_n_mads(10), everything()) %>%
  group_by(cyl) %>%
  summarise(avg.mpg=mean(mpg))
```


If you look closely, the last two lines in the above chunk are our analysis, but everything before it are assertions.

**Exercise:** Let's do an assertr analysis pipeline with the starwars dataset

```{r}
library(dplyr)
head(starwars)
```

What are some things we might want to analyze?

- Average height/mass by species/gender/homeworld?

What are some things we might like to assert *before* we do that analysis?

- birth_year/height/mass is a positive real number
- no Droids should have Gender (maybe)?

## Summary

- There are a number of ways to munge and qc data with base R
- The `tidyr` package provides a few very useful functions that do things not easily done in base R
- The `assertr` package shows a new methodology where the assertions are built into the analysis pipeline

## Misc

Data generation:

```{r}
n <- 6
reps <- 10
fundata <- data.frame(site = rep(rep(c("A", "B", "C", "D", "E", "F"), n), reps),
                      plot = rep(rep(c(1:6), n), reps),
                      temp_c = rnorm(n * n * reps, 30, 5))

# omit 5 rows at random
fundata <- fundata[-sample(1:nrow(fundata), 5, replace = FALSE),]

# replace 5 values with -999
fundata[sample(1:nrow(fundata), 5, replace = FALSE), "temp_c"] <- -9999

# replace 1 value with a way-too-high value
fundata[sample(1:nrow(fundata), 1), "temp_c"] <- 180

# replace 1 site with NA
fundata[sample(1:nrow(fundata), 1), "site"] <- NA

# mush site and plot together into one column
fundata$siteplot <- paste(fundata$site, fundata$plot, sep = ".")

# clean it up and save it
fundata <- fundata[,c("siteplot", "temp_c")]
write.csv(fundata, row.names = FALSE, file = "fundata.csv")
```